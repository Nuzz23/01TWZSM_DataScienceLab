{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODULES, IMPORTS, LIBRARIES AND CONSTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### modules, libraries and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE READING\n",
    "from os import listdir\n",
    "from torchaudio.transforms import Spectrogram, AmplitudeToDB\n",
    "from torchaudio import load\n",
    "from torch import Tensor\n",
    "\n",
    "# Fundamentals\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# METRICS\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from seaborn import heatmap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading constants\n",
    "DATA_PATH = './data/dev/'\n",
    "METRICS_W_PARAM={accuracy_score:None, balanced_accuracy_score:None,\n",
    "                    recall_score:{'average':'macro'}, precision_score:{'average':'macro'}, f1_score:{'average':'macro'}}\n",
    "\n",
    "\n",
    "# Classifiers Chosen\n",
    "CLASSIFIERS = [ RandomForestClassifier(**{'criterion': 'entropy', 'n_estimators': 200}),\n",
    "                KNeighborsClassifier(**{'algorithm': 'auto', 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}),\n",
    "                SVC(**{'degree': 3, 'kernel': 'linear', 'probability': True})\n",
    "                ]\n",
    "CLASSIFIERS_ACCURACY = [ 0.9643542782442616, 0.9601806787239386, 0.97221804903412] \n",
    "BEST_ROWS = 26\n",
    "BEST_COLS = 4\n",
    "\n",
    "# Classification and output on file\n",
    "EVAL_INPUT_DATA_PATH = './data/eval/'\n",
    "OUTPUT_FILE = './prediction/myPrediction.csv'\n",
    "\n",
    "\n",
    "# DATA AUGMENTATION\n",
    "AUGMENT_DATA = False\n",
    "AUGMENTED_DATA_PATH = \"./data/dataAugmentation/recordings/\"\n",
    "OUTPUT_AUGMENTED_FILE = './prediction/myPredictionAUG.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILE READ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads the file in the given path and returns:\n",
    "- reads the file and evaluates the spectrogram in db for each wav file\n",
    "- reads the class associated to the file and returns a series using as index the file name and as values the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataAsSpectrogram(path:str)->dict[str:Tensor]:\n",
    "    return {file:AmplitudeToDB()(Spectrogram()(load(path+file)[0]))[0] for file in listdir(path) if file.endswith('.wav')}\n",
    "\n",
    "def loadDataClasses(path:str)->pd.Series:\n",
    "    return pd.Series({file:file.split(\"_\")[-1].split('.')[0] for file in listdir(path) if file.endswith('.wav')}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads the augmented data:\n",
    "- Returns the spectrogram of the augmented data\n",
    "- Returns the classes of the augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAugmentedDataAsSpectrogram(path:str)->dict[str:Tensor]:\n",
    "    return {file:AmplitudeToDB()(Spectrogram()(load(path+file)[0]))[0] for file in listdir(path) if file.endswith('.wav')}\n",
    "\n",
    "def loadAugmentedDataClasses(path:str)->pd.Series:\n",
    "    return pd.Series({file:file.split(\"_\")[0] for file in listdir(path) if file.endswith('.wav')}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPUTE SUB MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divides the spectrogram matrix into sub matrix (such that there are rows*cols sub matrix) and each one of this sub matrix is then summed up by means of the mean value and the standard deviation. <br> All the sub matrices are disjoint\n",
    "<br> Also the sub matrix are then reshaped to be a one dimensional vector using a row major philosophy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSubMatrix(data:Tensor, rows:int, cols:int)->dict[str:np]:\n",
    "    return ({key:np.array([data[key][data[key].shape[0]//rows * i: min(data[key].shape[0]//rows * (i+1), data[key].shape[0]), data[key].shape[1]//cols * j: min(data[key].shape[1]//cols * (j+1), data[key].shape[1])].mean() for i in range(rows) for j in range(cols)]) for key in data},\n",
    "            {key:np.array([data[key][data[key].shape[0]//rows * i: min(data[key].shape[0]//rows * (i+1), data[key].shape[0]), data[key].shape[1]//cols * j: min(data[key].shape[1]//cols * (j+1), data[key].shape[1])].std() for i in range(rows) for j in range(cols)]) for key in data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE DATAFRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataframe is created having as rows the file name (index) and as columns the mean and the standard deviation of the sub matrices, which are one dimensionally stretched out, the first columns are relative to the mean, the others to the standard deviation.\n",
    "<br>\n",
    "The function can work with either a tuple containing both mean and std or with the two parameter passed separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDf(mean_std:dict[str:np], std:dict[str:np]=False)->pd.DataFrame:\n",
    "    return pd.concat([pd.DataFrame(mean_std if std else mean_std[0]), pd.DataFrame(std if std else mean_std[1])], axis=0).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN THE CLASSIFIERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector of classifier is trained and then is used to predict the data values <br>\n",
    "The prediction is then returned as a dataframe having as indexes the name of the files and as columns the classifier used <br>\n",
    "in each cell there is the prediction for said file and said classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildClassifiers(classifiers:list[RandomForestClassifier], xTrain:pd.DataFrame, yTrain:pd.Series, xPred:pd.Series)->pd.DataFrame:\n",
    "    return pd.DataFrame([clf.fit(xTrain, yTrain).predict(xPred) for clf in classifiers], columns=xPred.index, index=[str(clf).split('(')[0] for clf in classifiers]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REDUCE THE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduces the classification by implementing a weighted majority voting algorithm, where the weight were previously defined by the sole model f1_score during the validation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceToOneClass(df:pd.DataFrame, clfAcc:list)->pd.DataFrame:\n",
    "    diz = {}\n",
    "    for index in df.index:\n",
    "        temp = np.zeros(10)\n",
    "        \n",
    "        for i in range(len(clfAcc)):\n",
    "            temp[int(df.loc[index, :].iloc[i])] += clfAcc[i]\n",
    "        \n",
    "        diz[index] = temp.argmax()\n",
    "    \n",
    "    return pd.Series(diz, index=df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT SIGNAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plots a given signal by the index of it in the time domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSignal(df:pd.DataFrame, index:str)->None:\n",
    "    fig, ax = plt.subplot(figsize=(10,10))\n",
    "    ax.set_title(index)\n",
    "    ax.plot(df.columns.difference(['class', 'energy', 'power']).sort_values(), \n",
    "        df.loc[index, df.columns.difference(['class', 'energy', 'power'])])\n",
    "    \n",
    "    ax.grid(visible=True)\n",
    "    plt.show()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "def plotMultipleSignal(df: pd.DataFrame, index:list[str])->None:\n",
    "    fig, ax = plt.subplots(len(index)//2 + (1 if len(index) % 2 else 0), 2,figsize=(20,40))\n",
    "    for j in range(2):\n",
    "        for i in range(len(index)//2 + (1 if len(index) % 2 else 0)): \n",
    "            if j*2+i < len(index):\n",
    "                ax[i,j].set_title(index[j*2+i])\n",
    "                ax[i,j].plot(df.columns.difference(['class', 'energy', 'power']).sort_values(), \n",
    "                    df.loc[index[j*2+i], df.columns.difference(['class', 'energy', 'power'])])\n",
    "                \n",
    "                ax[i,j].grid(visible=True)\n",
    "                \n",
    "    plt.show()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIGNAL POWER AND ENERGY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The signal power and energy are here calculated per each signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addEnergyAndPower(df:pd.DataFrame, plot:bool=False)->pd.DataFrame:\n",
    "    df['energy'] = df.loc[:, df.columns.difference(['class'])].apply(func=lambda x: x**2).sum(axis=1)**0.5\n",
    "    df = pd.concat([df, pd.Series(data=[df.loc[index, 'energy']/(df.loc[index,:].dropna().shape[0]-2) for index in df.index], index=df.index, name='power'), ], axis=1)\n",
    "    \n",
    "    if plot:\n",
    "        fig, ax = plt.subplots(2,1, figsize=(20,10))\n",
    "        ax[0].scatter(df['class'], df['energy']) \n",
    "        ax[0].set_title('Class vs Energy') \n",
    "        ax[0].set_xlabel('Class')\n",
    "        ax[0].set_ylabel('Energy')\n",
    "        \n",
    "        ax[1].scatter(df['class'], df['power']) \n",
    "        ax[1].set_title('Class vs Power') \n",
    "        ax[1].set_xlabel('Class')\n",
    "        ax[1].set_ylabel('Power')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST METRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests all useful metrics on a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testAllMetrics(yTrue:pd.DataFrame|pd.Series, yPred:pd.DataFrame|pd.Series, metrics: dict, printConfusionMatrix:bool=False)->pd.DataFrame:\n",
    "    if printConfusionMatrix:\n",
    "        heatmap(confusion_matrix(yTrue, yPred), annot=True)\n",
    "    return pd.DataFrame({str(metric).split()[1]:metric(yTrue, yPred, **metrics[metric]) if metrics[metric] else metric(yTrue, yPred) for metric in metrics}, \n",
    "                        index=['values'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main function that coordinates all the execution of the program, that is used for building and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utente\\AppData\\Local\\Temp\\ipykernel_17096\\746784652.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return df.apply(lambda row: np.argmax(np.array([sum(clfAcc[int(row[i])] if i < len(clfAcc) else 0 for i in range(len(row)))])), axis=1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[199], line 8\u001b[0m\n\u001b[0;32m      2\u001b[0m     Xtrain, Xtest, Ytrain, Ytest \u001b[38;5;241m=\u001b[39m train_test_split(createDf(createSubMatrix(loadDataAsSpectrogram(DATA_PATH), BEST_ROWS, BEST_COLS))\u001b[38;5;241m.\u001b[39msort_index(), \n\u001b[0;32m      3\u001b[0m                                                     loadDataClasses(DATA_PATH)\u001b[38;5;241m.\u001b[39msort_index(), test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.20\u001b[39m)\n\u001b[0;32m      5\u001b[0m     display(testAllMetrics(Ytest, reduceToOneClass(BuildClassifiers(CLASSIFIERS, Xtrain, Ytrain, Xtest), CLASSIFIERS_ACCURACY),\n\u001b[0;32m      6\u001b[0m                             metrics\u001b[38;5;241m=\u001b[39mMETRICS_W_PARAM, printConfusionMatrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m----> 8\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[199], line 5\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m()\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m:        \n\u001b[0;32m      2\u001b[0m     Xtrain, Xtest, Ytrain, Ytest \u001b[38;5;241m=\u001b[39m train_test_split(createDf(createSubMatrix(loadDataAsSpectrogram(DATA_PATH), BEST_ROWS, BEST_COLS))\u001b[38;5;241m.\u001b[39msort_index(), \n\u001b[0;32m      3\u001b[0m                                                     loadDataClasses(DATA_PATH)\u001b[38;5;241m.\u001b[39msort_index(), test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.20\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     display(testAllMetrics(Ytest, \u001b[43mreduceToOneClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBuildClassifiers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCLASSIFIERS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLASSIFIERS_ACCURACY\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m      6\u001b[0m                             metrics\u001b[38;5;241m=\u001b[39mMETRICS_W_PARAM, printConfusionMatrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "Cell \u001b[1;32mIn[198], line 2\u001b[0m, in \u001b[0;36mreduceToOneClass\u001b[1;34m(df, clfAcc)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduceToOneClass\u001b[39m(df:pd\u001b[38;5;241m.\u001b[39mDataFrame, clfAcc:\u001b[38;5;28mlist\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfAcc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfAcc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\utente\\OneDrive\\Desktop\\Magistrale\\01TWZSM_DataScienceLab\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\utente\\OneDrive\\Desktop\\Magistrale\\01TWZSM_DataScienceLab\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\utente\\OneDrive\\Desktop\\Magistrale\\01TWZSM_DataScienceLab\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\utente\\OneDrive\\Desktop\\Magistrale\\01TWZSM_DataScienceLab\\.venv\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[198], line 2\u001b[0m, in \u001b[0;36mreduceToOneClass.<locals>.<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduceToOneClass\u001b[39m(df:pd\u001b[38;5;241m.\u001b[39mDataFrame, clfAcc:\u001b[38;5;28mlist\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: np\u001b[38;5;241m.\u001b[39margmax(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfAcc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclfAcc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m])), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[198], line 2\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduceToOneClass\u001b[39m(df:pd\u001b[38;5;241m.\u001b[39mDataFrame, clfAcc:\u001b[38;5;28mlist\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: np\u001b[38;5;241m.\u001b[39margmax(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28msum\u001b[39m(\u001b[43mclfAcc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(clfAcc) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(row)))])), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def main()->None:        \n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(createDf(createSubMatrix(loadDataAsSpectrogram(DATA_PATH), BEST_ROWS, BEST_COLS)).sort_index(), \n",
    "                                                    loadDataClasses(DATA_PATH).sort_index(), test_size=0.20)\n",
    "\n",
    "    display(testAllMetrics(Ytest, reduceToOneClass(BuildClassifiers(CLASSIFIERS, Xtrain, Ytrain, Xtest), CLASSIFIERS_ACCURACY),\n",
    "                            metrics=METRICS_W_PARAM, printConfusionMatrix=True))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTION FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to classify the eval data (even supporting data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify():\n",
    "    if AUGMENT_DATA:\n",
    "        # Loads data\n",
    "        data = loadAugmentedDataAsSpectrogram(AUGMENTED_DATA_PATH)\n",
    "        data.update(loadDataAsSpectrogram(DATA_PATH))\n",
    "        \n",
    "        # Note all this code is done in one row for compactness\n",
    "        # Loads classes\n",
    "        # classes= pd.concat([loadAugmentedDataClasses(AUGMENTED_DATA_PATH), loadDataClasses(DATA_PATH)], axis=0).sort_index()\n",
    "        \n",
    "        # Updates the data\n",
    "        # df = createDf(createSubMatrix(data), BEST_ROWS, BEST_COLS).sort_index()\n",
    "        \n",
    "        yPred = reduceToOneClass(BuildClassifiers(CLASSIFIERS, \n",
    "                                                    createDf(createSubMatrix(data, BEST_ROWS, BEST_COLS)).sort_index(), \n",
    "                                                    pd.concat([loadAugmentedDataClasses(AUGMENTED_DATA_PATH), loadDataClasses(DATA_PATH)], axis=0).sort_index(), \n",
    "                                createDf(\n",
    "                                    createSubMatrix(loadDataAsSpectrogram(EVAL_INPUT_DATA_PATH), BEST_ROWS, BEST_COLS)\n",
    "                                    ).sort_index()), CLASSIFIERS_ACCURACY)\n",
    "    else:\n",
    "        df = createDf(createSubMatrix(loadDataAsSpectrogram(DATA_PATH), BEST_ROWS, BEST_COLS)).sort_index()\n",
    "        classes = loadDataClasses(DATA_PATH).sort_index()\n",
    "        yPred = reduceToOneClass(BuildClassifiers(CLASSIFIERS, df, classes, \n",
    "                            createDf(createSubMatrix(\n",
    "                                loadDataAsSpectrogram(EVAL_INPUT_DATA_PATH), BEST_ROWS, BEST_COLS) \n",
    "                                    ).sort_index()), CLASSIFIERS_ACCURACY)\n",
    "    \n",
    "    \n",
    "    yPred.set_axis(labels=list(map(lambda x: int(str(x).split('.')[0]),  yPred.index)), axis='index').sort_index().to_csv(path_or_buf=OUTPUT_AUGMENTED_FILE if AUGMENT_DATA else OUTPUT_FILE)\n",
    "    \n",
    "\n",
    "classify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING MODELS AND HYPER PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the best configuration for the number of matrix per each element rows and columns by f1_score metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testingConfigMatrix()->set[int, int, float]: \n",
    "    classes = loadDataClasses(DATA_PATH)\n",
    "    df = loadDataAsSpectrogram(DATA_PATH)\n",
    "    maximum = set()\n",
    "    for i in range(20, 80, 3):\n",
    "        for j in range(3, 7):\n",
    "            try:\n",
    "                data = createDf(createSubMatrix(df, i, j))\n",
    "            except Exception:\n",
    "                print(i, j, ' key error')\n",
    "                continue\n",
    "\n",
    "            \n",
    "            if set(data.count()) != {1500}:\n",
    "                print(i, j, ' has np.nan')\n",
    "                continue\n",
    "\n",
    "            Xtrain, Xtest, Ytrain, Ytest = train_test_split(data.sort_index(), classes.sort_index(), test_size=0.20)\n",
    "\n",
    "\n",
    "            temp = reduceToOneClass(BuildClassifiers(CLASSIFIERS, Xtrain, Ytrain, Xtest), CLASSIFIERS_ACCURACY)\n",
    "\n",
    "            maximum.add((i, j, f1_score(Ytest, temp,average='macro')))\n",
    "    \n",
    "    return maximum\n",
    "\n",
    "for line in sorted(testingConfigMatrix(), key=lambda x: x[2], reversed=True):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the optimal configuration of different models by f1_score metric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest classifier \n",
    "BEST: 0.9643542782442616 {'criterion': 'entropy', 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min0 = 0\n",
    "\n",
    "for param in ParameterGrid(param_grid={\n",
    "    'n_estimators':list(range(100, 800, 100)),\n",
    "    'criterion':['gini', 'log_loss', 'entropy']\n",
    "}):\n",
    "    f1 = f1_score(Ytest, RandomForestClassifier(**param).fit(Xtrain, Ytrain).predict(Xtest), average='macro')\n",
    "    if f1 > min0:\n",
    "        min0 = f1\n",
    "        parameter = param\n",
    "\n",
    "print(min0, parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC CLASSIFIER \n",
    "BEST:0.97221804903412 {'degree': 3, 'kernel': 'linear', 'probability': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min2=0\n",
    "for param in ParameterGrid(param_grid={\n",
    "    'kernel':['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree':list(range(3, 10)),\n",
    "    'probability':[True, False],\n",
    "}):\n",
    "    f1 = f1_score(Ytest, SVC(**param).fit(Xtrain, Ytrain).predict(Xtest), average='macro')\n",
    "    if f1 > min2:\n",
    "        min2 = f1\n",
    "        parameter2 = param\n",
    "\n",
    "print(min2, parameter2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k nearest neighbors classifier\n",
    "Best  0.9601806787239386 {'algorithm': 'auto', 'n_neighbors': 5, 'p': 1, 'weights': 'distance'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min2=0\n",
    "for param in ParameterGrid(param_grid={\n",
    "    'n_neighbors':[5, 10, 20, 30],\n",
    "    'weights':['uniform', 'distance'],\n",
    "    'algorithm':['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p':[1,2,3]\n",
    "}):\n",
    "    f1 = f1_score(Ytest, KNeighborsClassifier(**param).fit(Xtrain, Ytrain).predict(Xtest), average='macro')\n",
    "    if f1 > min2:\n",
    "        min2 = f1\n",
    "        parameter2 = param\n",
    "\n",
    "print(min2, parameter2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree classifier\n",
    "\n",
    "0.70690466016627 {'criterion': 'log_loss', 'max_depth': 10, 'splitter': 'random'}<br>\n",
    "0.6976586924578915 {'criterion': 'entropy', 'max_depth': 10, 'splitter': 'random'}<br>\n",
    "NOTE: tested but not used due to low f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "min3 = 0\n",
    "\n",
    "for param in ParameterGrid(param_grid={\n",
    "    'criterion':['gini', 'entropy', 'log_loss'] ,\n",
    "    'splitter':['best', 'random'],\n",
    "    'max_depth':[None, 4, 8, 10,]\n",
    "}):\n",
    "    f1 = f1_score(Ytest, DecisionTreeClassifier(**param).fit(Xtrain, Ytrain).predict(Xtest), average='macro')\n",
    "    if f1 > min3:\n",
    "        min3 = f1\n",
    "        parameter3 = param\n",
    "\n",
    "print(min3, parameter3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
