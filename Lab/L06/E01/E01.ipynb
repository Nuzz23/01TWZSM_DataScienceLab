{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 - MODULES AND CONSTANTS\n",
    "All the modules, constants, import and libraries used in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from seaborn import heatmap\n",
    "\n",
    "## Imports from sklearn\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "DATA_INPUT_FILE = 'wine.data'\n",
    "CLASSES = ['class']\n",
    "FEATURE_NAMES = ['Alcohol', 'Malicacid', 'Ash', 'Alcalinity_of_ash', 'Magnesium', 'Total_phenols', 'Flavanoids', 'Nonflavanoid_phenols',\n",
    "'Proanthocyanins', 'Color_intensity', 'Hue', '0D280_0D315_of_diluted_wines', 'Proline']\n",
    "TEST_DATA_PERCENTAGE=0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - DATASET LOADING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset from sklearn, as described in Subsec. Then, based on your X and y, answer\n",
    "the following questions:\n",
    "- How many records are available?\n",
    "- Are there missing values?\n",
    "- How many elements does each class contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataBase(file:str, cols:list[str])->pd.DataFrame:\n",
    "    return pd.read_csv(filepath_or_buffer=file, delimiter=',', header=None, names=cols)\n",
    "\n",
    "def AnsQuestionPart1(df:pd.DataFrame)->None:\n",
    "    print('How many records are available ? \\t', df.shape[0])\n",
    "    print('Are there missing values ? \\n', df[df.isna()].count())\n",
    "    print('How many elements does each class contain? \\t', df.loc[:, 'class'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - CLASSIFIER BUILDING AND TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DecisionTreeClassifier object with the default configuration (i.e. without passing any\n",
    "parameters to the constructor). <br>Train the classifier using your X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAndTrainTree(df:pd.DataFrame, features:list[str], classes:list[str])->DecisionTreeClassifier:\n",
    "    tree = DecisionTreeClassifier()\n",
    "    tree.fit(X=df.loc[:, features], y=df.loc[:, classes])\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - TREE PLOTTING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have created a tree, you can visualize it. Sklearn offers two functions to visualize decision trees. \n",
    "<ul>\n",
    "<li>The first one, plot_tree(), plots the tree in a matplotlib-based, interactive window.</li>\n",
    "<li>An alternative way is using export_graphviz(). This function exports the tree as a DOT file. DOT\n",
    "is a language for describing graph (and, as a consequence, trees). From the DOT code, you can\n",
    "generate the resulting visual representation either using specific Python libraries, or by using any\n",
    "online tools (such as Webgraphviz). </li>\n",
    "</ul>\n",
    "We recommend using the latter approach, where you paste the string returned by export_graphviz (which is the DOT file) directly into Webgraphviz.<br> If, instead, you would rather run it locally, you can install pydot (Python package) and graphviz (a graph\n",
    "visualization software). <br>\n",
    "After you successfully plotted a tree, you can take a closer look at the result and draw some conclusions. \n",
    "<br> In particular, what information is contained in each node? Take a closer look at the leaf\n",
    "nodes. <br>Based on what you know about over fitting, what can you learn from these nodes?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: this import are only used here, so they will be exceptionally defined here\n",
    "from pydot import graph_from_dot_data\n",
    "from IPython.display import Image\n",
    "\n",
    "def printTree(tree:DecisionTreeClassifier, features:list[str], printGood:bool)->None:\n",
    "    if printGood:\n",
    "        dot_code = export_graphviz(tree, feature_names=features)\n",
    "        Image(graph_from_dot_data(dot_code)[0].create_png())\n",
    "    else:\n",
    "        plot_tree(tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - PREDICTION FOR OVER FITTING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the dataset X, you can get the predictions of the classifier (one for each entry in X) by calling\n",
    "the predict() of DecisionTreeClassifier. <br>\n",
    "Then, use the accuracy_score() function (which you can import from sklearn.metrics) to compute the accuracy between two lists of values (y_true,\n",
    "the list of “correct” labels, and y_pred, the list of predictions made by the classifier). \n",
    "<br> Since you already have both these lists (y for the ground truth, and the result of the predict() method for the\n",
    "prediction), you can already compute the accuracy of your classifier. \n",
    "<br> What result do you get? \n",
    "<br> Does this result seem particularly high/low? \n",
    "<br> Why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testOverFittingValues(tree:DecisionTreeClassifier, df:pd.DataFrame, classes:list[str], features:list[str], method: object) -> float:\n",
    "    return method(df.loc[:, classes], tree.predict(df.loc[:, features])) *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - PARTITIONED DATA SET TESTING AND ACCURACY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, we can split our dataset into a training set and a test set. <br>\n",
    "We will use the training set to train a model, and to assess its performance with the test set. <br>\n",
    "Sklearn offers the train_test_split() function to split any number of arrays (all having the same length on the first dimension) into two\n",
    "sets. <br> You can use an 80/20 train/test split. If used correctly, you will get 4 arrays: X_train, X_test, y_train, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitionAndTest(tree:DecisionTreeClassifier, df:pd.DataFrame, classes:list[str], features:list[str], testPercentage:float)->float:\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(df.loc[:, features], df.loc[:, classes], test_size=testPercentage)\n",
    "    tree.fit(xTrain, yTrain)\n",
    "    yPred = tree.predict(xTest)\n",
    "    \n",
    "    heatmap(confusion_matrix(yTest, yPred), annot=True)\n",
    "    \n",
    "    return round(accuracy_score(yTest, yPred),3)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 -  ADVANCED METRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train a new model using (X_train, y_train). Then, compute the accuracy with (X_test,y_test). \n",
    "<br> How does this value compare to the previously computed one? Is this a more reasonable value? Why? <br>\n",
    "\n",
    "This should give you a good idea as to why training and testing on the same dataset returns meaningless results. \n",
    "\n",
    "You can also compute other metrics (e.g. precision, recall, F1 score) using the respective functions (precision_score, recall_score, f1_score). <br> Note that, since these three metrics are all based on a single class, you can either compute the value for a single class, aggregate\n",
    "the results into a single value, or receive the results for all three classes. \n",
    "<br>You can also use the classification_report function, which returns various metrics (including the previously mentioned ones) for each of the\n",
    "classes of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitionAndTestWithAdvancedMetrics(tree:DecisionTreeClassifier, df:pd.DataFrame, classes:list[str], \n",
    "                                        features:list[str], testPercentage:float)->dict[str:float]:\n",
    "        \n",
    "        xTrain, XTest, yTrain, yTest = train_test_split(df.loc[:, features], df.loc[:, classes], test_size=testPercentage)\n",
    "        tree.fit(xTrain, yTrain)\n",
    "        yPred = tree.predict(XTest)\n",
    "        \n",
    "        heatmap(confusion_matrix(yTest, yPred), annot=True)\n",
    "        \n",
    "        return {'accuracy_score':accuracy_score(yTest, yPred), 'balanced_accuracy_score':balanced_accuracy_score(yTest, yPred),\n",
    "                'balanced_accuracy_score_adjusted':balanced_accuracy_score(yTest, yPred, adjusted=True), \n",
    "                'f1_score':f1_score(yTest, yPred, labels=[1,2,3], average=None), 'recall_score':recall_score(yTest, yPred, average=None), \n",
    "                'precision_score':precision_score(yTest, yPred, average=None)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - ADVANCED TREE SETTINGS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, you have only used “default” decision trees, but, the “default” decision tree might not be the best option in terms of performance to fit our dataset. <br>\n",
    "In this exercise, you will perform a “grid search”: you will define a set of possible configurations and, for each configuration, build a classifier. Then, you will test the performance of each classifier and identify that configuration that produces the best model.<br>\n",
    "On the official documentation for DecisionTreeClassifier you can find a list of all parameters you\n",
    "can modify. Identify some of the parameters that, based on your theoretical knowledge of decision\n",
    "trees, might affect the performance of the tree. <br>\n",
    "For each of these parameters, define a set of possible\n",
    "values (the official documentation provides additional information about the possible values that can\n",
    "be used). For example, we can identify these two parameters:\n",
    "<ul>\n",
    "<li><b>max_depth</b>: which defines the maximum depth of the decision tree, can be set to None (i.e.\n",
    "unbounded depth), or to values such as 2, 4, 8 (we already know from previous exercises the\n",
    "approximate depth the tree can reach with this dataset) </li>\n",
    "<li><b>splitter</b>: which can be set to either best (in which case, for each split, the algorithm will try\n",
    "all possible splits), or random (in this case, the algorithm will try N random splits on various\n",
    "features and select the best one)\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "You can and should identify additional parameters and possible values for them. Then, you can\n",
    "build a parameter dictionary (i.e. a dictionary where keys are parameter names and values are lists\n",
    "of candidate values). Using the ParameterGrid class offered by scikit-learn, you can generate a list\n",
    "of all possible configurations that can be obtained from the parameter dictionary.<br>\n",
    "For each configuration config, we can train a separate model with our training data, and validate\n",
    "it with our test data: for each configuration, compute the resulting accuracy on the test data. Then,\n",
    "select the parameter configuration having highest accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advancedTreeBuilding(df: pd.DataFrame):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN FUNCTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the main function of our program that will coordinate code execution, it does:\n",
    "<ol>\n",
    "<li>Loads the database into a data structure</li>\n",
    "<li>Creates and trains the classifier</li>\n",
    "<li>Prints the tree</li>\n",
    "<li>Accuracy evaluation for over fitting</li>\n",
    "<li>Model testing with partitioned data set</li>\n",
    "<li>Advanced metrics</li>\n",
    "<li>Advanced and custom tree classifier usage</li>\n",
    "<li></li>\n",
    "<li></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>balanced_accuracy_score</th>\n",
       "      <th>balanced_accuracy_score_adjusted</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>precision_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.805047</td>\n",
       "      <td>0.70757</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.805047</td>\n",
       "      <td>0.70757</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.805047</td>\n",
       "      <td>0.70757</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_score  balanced_accuracy_score  balanced_accuracy_score_adjusted  \\\n",
       "0        0.805556                 0.805047                           0.70757   \n",
       "1        0.805556                 0.805047                           0.70757   \n",
       "2        0.805556                 0.805047                           0.70757   \n",
       "\n",
       "   f1_score  recall_score  precision_score  \n",
       "0  0.888889      0.923077         0.857143  \n",
       "1  0.740741      0.714286         0.769231  \n",
       "2  0.777778      0.777778         0.777778  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main()->None:\n",
    "    df = loadDataBase(DATA_INPUT_FILE, CLASSES+FEATURE_NAMES) # 1\n",
    "    # AnsQuestionPart1(df) # 1\n",
    "    \n",
    "    tree = createAndTrainTree(df, FEATURE_NAMES, classes=['class']) # 2\n",
    "    \n",
    "    # printTree(tree, FEATURE_NAMES, False) # 3\n",
    "    \n",
    "    # print(\"'DUMB' Accuracy of the model \", testOverFittingValues(tree, df, CLASSES, FEATURE_NAMES, accuracy_score)) # 4\n",
    "    \n",
    "    # print(\"final accuracy = \", partitionAndTest(DecisionTreeClassifier(), df, CLASSES, FEATURE_NAMES, TEST_DATA_PERCENTAGE)) # 5\n",
    "    \n",
    "    # display(pd.DataFrame(partitionAndTestWithAdvancedMetrics(DecisionTreeClassifier(), df, CLASSES, FEATURE_NAMES, TEST_DATA_PERCENTAGE))) # 6\n",
    "    \n",
    "    advancedTreeBuilding(df)\n",
    "    \n",
    "    \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
