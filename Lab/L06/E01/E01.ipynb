{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 - MODULES AND CONSTANTS\n",
    "All the modules, constants, import and libraries used in this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from pydot import graph_from_dot_data\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "DATA_INPUT_FILE = 'wine.data'\n",
    "CLASSES = ['class']\n",
    "FEATURE_NAMES = ['Alcohol', 'Malicacid', 'Ash', 'Alcalinity_of_ash', 'Magnesium', 'Total_phenols', 'Flavanoids', 'Nonflavanoid_phenols',\n",
    "'Proanthocyanins', 'Color_intensity', 'Hue', '0D280_0D315_of_diluted_wines', 'Proline']\n",
    "DATA_PERCENTAGE = {'TRAIN':0.8, 'TEST':0.2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - DATASET LOADING\n",
    "\n",
    "Load the dataset from sklearn, as described in Subsec. Then, based on your X and y, answer\n",
    "the following questions:\n",
    "- How many records are available?\n",
    "- Are there missing values?\n",
    "- How many elements does each class contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataBase(file:str, cols:list[str])->pd.DataFrame:\n",
    "    return pd.read_csv(filepath_or_buffer=file, delimiter=',', header=None, names=cols)\n",
    "\n",
    "def AnsQuestionPart1(df:pd.DataFrame)->None:\n",
    "    print('How many records are available ? \\t', df.shape[0])\n",
    "    print('Are there missing values ? \\n', df[df.isna()].count())\n",
    "    print('How many elements does each class contain? \\t', df.loc[:, 'class'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - CLASSIFIER BUILDING AND TRAINING\n",
    "Create a DecisionTreeClassifier object with the default configuration (i.e. without passing any\n",
    "parameters to the constructor). <br>Train the classifier using your X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAndTrainTree(df:pd.DataFrame, features:list[str], classes:list[str])->DecisionTreeClassifier:\n",
    "    tree = DecisionTreeClassifier()\n",
    "    tree.fit(X=df.loc[:, features], y=df.loc[:, classes])\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - TREE PLOTTING\n",
    "Now that you have created a tree, you can visualize it. Sklearn offers two functions to visualize decision trees. \n",
    "<ul>\n",
    "<li>The first one, plot_tree(), plots the tree in a matplotlib-based, interactive window.</li>\n",
    "<li>An alternative way is using export_graphviz(). This function exports the tree as a DOT file. DOT\n",
    "is a language for describing graph (and, as a consequence, trees). From the DOT code, you can\n",
    "generate the resulting visual representation either using specific Python libraries, or by using any\n",
    "online tools (such as Webgraphviz). </li>\n",
    "</ul>\n",
    "We recommend using the latter approach, where you paste the string returned by export_graphviz (which is the DOT file) directly into Webgraphviz.<br> If, instead, you would rather run it locally, you can install pydot (Python package) and graphviz (a graph\n",
    "visualization software). <br>\n",
    "After you successfully plotted a tree, you can take a closer look at the result and draw some conclusions. \n",
    "<br> In particular, what information is contained in each node? Take a closer look at the leaf\n",
    "nodes. <br>Based on what you know about over fitting, what can you learn from these nodes?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTree(tree:DecisionTreeClassifier, features:list[str], printGood:bool)->None:\n",
    "    if printGood:\n",
    "        dot_code = export_graphviz(tree, feature_names=features)\n",
    "        Image(graph_from_dot_data(dot_code)[0].create_png())\n",
    "    else:\n",
    "        plot_tree(tree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - PREDICTION FOR OVER FITTING \n",
    "\n",
    "Given the dataset X, you can get the predictions of the classifier (one for each entry in X) by calling\n",
    "the predict() of DecisionTreeClassifier. <br>\n",
    "Then, use the accuracy_score() function (which you can import from sklearn.metrics) to compute the accuracy between two lists of values (y_true,\n",
    "the list of “correct” labels, and y_pred, the list of predictions made by the classifier). \n",
    "<br> Since you already have both these lists (y for the ground truth, and the result of the predict() method for the\n",
    "prediction), you can already compute the accuracy of your classifier. \n",
    "<br> What result do you get? \n",
    "<br> Does this result seem particularly high/low? \n",
    "<br> Why do you think that is?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testOverFittingValues(tree:DecisionTreeClassifier, df:pd.DataFrame, classes:list[str], features:list[str], method: object) -> float:\n",
    "    return method(df.loc[:, classes], tree.predict(df.loc[:, features])) *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - PARTITIONED DATA SET TESTING AND ACCURACY\n",
    "\n",
    "Now, we can split our dataset into a training set and a test set. <br>\n",
    "We will use the training set to train a model, and to assess its performance with the test set. <br>\n",
    "Sklearn offers the train_test_split() function to split any number of arrays (all having the same length on the first dimension) into two\n",
    "sets. <br> You can use an 80/20 train/test split. If used correctly, you will get 4 arrays: X_train, X_test, y_train, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN FUNCTION\n",
    "this is the main function of our program that will coordinate code execution, it does:\n",
    "<ol>\n",
    "<li>Loads the database into a data structure</li>\n",
    "<li>Creates and trains the classifier</li>\n",
    "<li>Prints the tree</li>\n",
    "<li>Accuracy evaluation for over fitting</li>\n",
    "<li>Model testing with partitioned data set</li>\n",
    "<li></li>\n",
    "<li></li>\n",
    "<li></li>\n",
    "<li></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'DUMB' Accuracy of the model  100.0\n"
     ]
    }
   ],
   "source": [
    "def main()->None:\n",
    "    df = loadDataBase(DATA_INPUT_FILE, CLASSES+FEATURE_NAMES) # 1\n",
    "    # AnsQuestionPart1(df) # 1\n",
    "    \n",
    "    tree = createAndTrainTree(df, FEATURE_NAMES, classes=['class']) # 2\n",
    "    \n",
    "    # printTree(tree, FEATURE_NAMES, False) # 3\n",
    "    \n",
    "    print(\"'DUMB' Accuracy of the model \", testOverFittingValues(tree, df, CLASSES, FEATURE_NAMES, accuracy_score))\n",
    "    \n",
    "    \n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
